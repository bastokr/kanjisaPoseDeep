{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepLabCut/DeepLabCut/blob/main/examples/COLAB/COLAB_DLC_ModelZoo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RK255E7YoEIt"
      },
      "source": [
        "# **DeepLabCut Model Zoo!**\n",
        "\n",
        "![alt text](https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1616492373700-PGOAC72IOB6AUE47VTJX/ke17ZwdGBToddI8pDm48kB8JrdUaZR-OSkKLqWQPp_YUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYwL8IeDg6_3B-BRuF4nNrNcQkVuAT7tdErd0wQFEGFSnBqyW03PFN2MN6T6ry5cmXqqA9xITfsbVGDrg_goIDasRCalqV8R3606BuxERAtDaQ/modelzoo.png?format=1000w)\n",
        "\n",
        "http://modelzoo.deeplabcut.org\n",
        "\n",
        "You can use this notebook to analyze videos with pretrained networks from our model zoo - NO local installation of DeepLabCut is needed!\n",
        "\n",
        "- **What you need:** a video of your favorite dog, cat, human, etc: check the list of currently available models here: http://modelzoo.deeplabcut.org\n",
        "\n",
        "- **What to do:** (1) in the top right corner, click \"CONNECT\". Then, just hit run (play icon) on each cell below and follow the instructions!\n",
        "\n",
        "## **Please consider giving back and labeling a little data to help make each network even better!**\n",
        "\n",
        "We have a WebApp, so no need to install anything, just a few clicks! We'd really appreciate your help!\n",
        "   \n",
        "https://contrib.deeplabcut.org/\n",
        "\n",
        "\n",
        "- **Note, if you performance is less that you would like:** firstly check the labeled_video parameters (i.e. \"pcutoff\" in the config.yaml file that will set the video plotting) - see the end of this notebook. You can also use the model in your own projects locally. Please be sure to cite the papers for the model, and http://modelzoo.deeplabcut.org (paper forthcoming!)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **Let's get going: install DeepLabCut into COLAB:**\n",
        "\n",
        "*Also, be sure you are connected to a GPU: go to menu, click Runtime > Change Runtime Type > select \"GPU\"*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q23BzhA6CXxu",
        "outputId": "fda6995e-72d3-4ec6-a409-fe84919a99e0"
      },
      "outputs": [],
      "source": [
        "#click the play icon (this will take a few minutes to install all the dependencies!)\n",
        "#!pip install deeplabcut[tf,modelzoo]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "콘다 버전 설치 \n",
        "conda create -n  deep310 python=3.10.12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0tZRG_petkqp"
      },
      "outputs": [],
      "source": [
        "!rm -rf /home/skpark/git/pose-detection-keypoints-estimation-yolov8/deeplabcup/myDLC_modelZoo-teamDLC-2023-07-13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os \n",
        "os.chdir('/home/skpark/git/pose-detection-keypoints-estimation-yolov8/deeplabcup')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zYm6DljQB0Y7"
      },
      "source": [
        "###proTip: be sure to click \"restart runtime button\" if it appears above ^"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT4PwGSbYQEO"
      },
      "source": [
        "## Now let's set the backend & import the DeepLabCut package\n",
        "#### (if colab is buggy/throws an error, just rerun this cell):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvoiWefrYQEP",
        "outputId": "c445a18d-1f4d-498c-e30e-e6083bc129f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-14 21:01:14.642660: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-14 21:01:14.744469: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-07-14 21:01:15.210041: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2023-07-14 21:01:15.210080: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2023-07-14 21:01:15.210086: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading DLC 2.3.5...\n",
            "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import deeplabcut"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "syweXs88tyuO"
      },
      "source": [
        "## Next, run the cell below to upload your video file from your computer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        },
        "id": "7eqEZYs_CaLy",
        "outputId": "6f31f98b-659c-4ce4-99a1-a93684707455"
      },
      "outputs": [],
      "source": [
        "#from google.colab import files\n",
        "\n",
        "#uploaded = files.upload()\n",
        "#for filepath, content in uploaded.items():\n",
        "#  print(f'User uploaded file \"{filepath}\" with length {len(content)} bytes')\n",
        "video_path = os.path.abspath('/home/skpark/git/pose-detection-keypoints-estimation-yolov8/data/KakaoTalk_20230713_080931355.mp4')\n",
        "#video_path = '/content/1689199619487.mp4'\n",
        "# If this cell fails (e.g., when using Safari in place of Google Chrome),\n",
        "# manually upload your video via the Files menu to the left\n",
        "# and define `video_path` yourself with right click > copy path on the video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipywidgets in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (8.0.7)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from ipywidgets) (6.15.0)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from ipywidgets) (8.14.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.7 in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from ipywidgets) (4.0.8)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from ipywidgets) (3.0.8)\n",
            "Requirement already satisfied: debugpy>=1.0 in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.3.4)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
            "Requirement already satisfied: nest-asyncio in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.6)\n",
            "Requirement already satisfied: packaging in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (23.1)\n",
            "Requirement already satisfied: psutil in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: tornado>=6.1 in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
            "Requirement already satisfied: backcall in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: decorator in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
            "Requirement already satisfied: pickleshare in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
            "Requirement already satisfied: stack-data in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: entrypoints in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
            "Requirement already satisfied: executing>=1.2.0 in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
            "Requirement already satisfied: pure-eval in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: six in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (3.8.1)\n"
          ]
        }
      ],
      "source": [
        "#!pip install ipywidgets"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YsaqOTkZtf-w"
      },
      "source": [
        "## Select your model from the dropdown menu, then below (optionally) input the name you want for the project:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c696e22edc8f495fb6c016f2bb5f34db",
            "78dea5d394ba43bfbb0609bbf412ffbd",
            "f0f13fb4865e47cabcd69119a984a83c"
          ]
        },
        "id": "Ih0t7lUjYQEd",
        "outputId": "ac1f819a-b62e-4452-a031-fac7e2ee1156"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfb07b949c084f76be214399804b3198",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dropdown(description='Choose a DLC ModelZoo model!', options=('full_human', 'full_cat', 'full_dog', 'primate_f…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "model_options = deeplabcut.create_project.modelzoo.Modeloptions\n",
        "model_selection = widgets.Dropdown(\n",
        "    options=model_options,\n",
        "    value=model_options[0],\n",
        "    description=\"Choose a DLC ModelZoo model!\",\n",
        "    disabled=False\n",
        ")\n",
        "display(model_selection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UV0QXswGCFrI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "full_dog\n"
          ]
        }
      ],
      "source": [
        "project_name = 'myDLC_modelZoo'\n",
        "your_name = 'teamDLC'\n",
        "\n",
        "print(model_selection.value)\n",
        "model2use = model_selection.value\n",
        "videotype = os.path.splitext(video_path)[-1].lstrip('.') #or MOV, or avi, whatever you uploaded!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JQxko-t3uMVO"
      },
      "source": [
        "## Attention on this step !!\n",
        "- Please note that for optimal performance your videos should contain frames that are around ~300-600 pixels (on one edge). If you have a larger video (like from an iPhone, first downsize by running this please! :)\n",
        "\n",
        "- Thus, if you're using an iPhone, or such, you'll need to downsample the video first by running the code below**\n",
        "\n",
        "(no need to edit it unless you want to change the size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WpAX3BKY94e0"
      },
      "outputs": [],
      "source": [
        "#video_path = deeplabcut.DownSampleVideo(video_path, width=300)\n",
        "#print(video_path)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KJm_Vbx-s5OY"
      },
      "source": [
        "## Lastly, run the cell below to create a pretrained project, analyze your video with your selected pretrained network, plot trajectories, and create a labeled video!:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877,
          "referenced_widgets": [
            "5e0a992bcd9c4a9f806cb8f46a82b1ec",
            "afdc333a374e48348ea9d50f7194336d",
            "43ca0107ea4142e2b80cc2918967a8c7",
            "deb40f754d8b44d8a4936f6dd95fa5e2",
            "b6d9c3ea1d2045d4b0969d12e2dbd52d",
            "1a65956563b5422189f053fb30a9cd63",
            "cfce8ea2d40f48469469682dc7600ffd",
            "efc725905dc2443ea97e1516a35932a0",
            "b785208d70a34d32a1b30f30497596f1",
            "85bee6c1211e4cfd90bbdbfb452238fb",
            "dc7e8b5e5bd94478863f4e20cb62de17"
          ]
        },
        "id": "T9MGgAdIFKPY",
        "outputId": "78e069af-02e0-4236-d5c1-4c74e1de614f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project \"/home/skpark/git/pose-detection-keypoints-estimation-yolov8/deeplabcup/myDLC_modelZoo-teamDLC-2023-07-14\" already exists!\n",
            "Downloading weights...\n",
            "Loading.... full_dog\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da67d9f3d01d4d6483de6ac79b98c605",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)n-0_shuffle-0.tar.gz:   0%|          | 0.00/183M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/skpark/git/pose-detection-keypoints-estimation-yolov8/deeplabcup/myDLC_modelZoo-teamDLC-2023-07-14/dlc-models/iteration-0/myDLC_modelZooJul14-trainset95shuffle1/train/pose_cfg.yaml\n",
            "Analyzing video...\n",
            "Using snapshot-75000 for model /home/skpark/git/pose-detection-keypoints-estimation-yolov8/deeplabcup/myDLC_modelZoo-teamDLC-2023-07-14/dlc-models/iteration-0/myDLC_modelZooJul14-trainset95shuffle1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/skpark/.conda/envs/deep310/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "2023-07-14 21:02:33.463479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-07-14 21:02:33.551708: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/skpark/.conda/envs/deep310/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-07-14 21:02:33.551723: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2023-07-14 21:02:33.551983: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-14 21:02:33.570347: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing all the videos in the directory...\n",
            "Starting to analyze %  /home/skpark/git/pose-detection-keypoints-estimation-yolov8/deeplabcup/myDLC_modelZoo-teamDLC-2023-07-14/videos/KakaoTalk_20230713_080931355.mp4\n",
            "Loading  /home/skpark/git/pose-detection-keypoints-estimation-yolov8/deeplabcup/myDLC_modelZoo-teamDLC-2023-07-14/videos/KakaoTalk_20230713_080931355.mp4\n",
            "Duration of video [s]:  6.62 , recorded with  24.0 fps!\n",
            "Overall # of frames:  159  found with (before cropping) frame dimensions:  640 360\n",
            "Starting to extract posture\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 159/159 [00:15<00:00, 10.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving results in /home/skpark/git/pose-detection-keypoints-estimation-yolov8/deeplabcup/myDLC_modelZoo-teamDLC-2023-07-14/videos...\n",
            "Saving csv poses!\n",
            "The videos are analyzed. Now your research can truly start! \n",
            " You can create labeled videos with 'create_labeled_video'\n",
            "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
            "Analyzing all the videos in the directory...\n",
            "Filtering with median model /home/skpark/git/pose-detection-keypoints-estimation-yolov8/deeplabcup/myDLC_modelZoo-teamDLC-2023-07-14/videos/KakaoTalk_20230713_080931355.mp4\n",
            "Saving filtered csv poses!\n",
            "Plotting results...\n",
            "Analyzing all the videos in the directory...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting to process video: /home/skpark/git/pose-detection-keypoints-estimation-yolov8/deeplabcup/myDLC_modelZoo-teamDLC-2023-07-14/videos/KakaoTalk_20230713_080931355.mp4\n",
            "Loading /home/skpark/git/pose-detection-keypoints-estimation-yolov8/deeplabcup/myDLC_modelZoo-teamDLC-2023-07-14/videos/KakaoTalk_20230713_080931355.mp4 and data.\n",
            "Duration of video [s]: 6.62, recorded with 24.0 fps!\n",
            "Overall # of frames: 159 with cropped frame dimensions: 640 360\n",
            "Generating frames and creating video.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 159/159 [00:00<00:00, 396.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing all the videos in the directory...\n",
            "Loading  /home/skpark/git/pose-detection-keypoints-estimation-yolov8/deeplabcup/myDLC_modelZoo-teamDLC-2023-07-14/videos/KakaoTalk_20230713_080931355.mp4 and data.\n",
            "Plots created! Please check the directory \"plot-poses\" within the video directory\n"
          ]
        }
      ],
      "source": [
        "config_path, train_config_path = deeplabcut.create_pretrained_project(\n",
        "    project_name,\n",
        "    your_name,\n",
        "    [video_path],\n",
        "    videotype=videotype,\n",
        "    model=model2use,\n",
        "    analyzevideo=True,\n",
        "    createlabeledvideo=True,\n",
        "    copy_videos=True, #must leave copy_videos=True\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WS-KxhBMvEBj"
      },
      "source": [
        "Now, you can move this project from Colab (i.e. download it to your GoogleDrive), and use it like a normal standard project!\n",
        "\n",
        "You can analyze more videos, extract outliers, refine then, and/or then add new key points + label new frames, and retrain if desired. We hope this gives you a good launching point for your work!\n",
        "\n",
        "###Happy DeepLabCutting! Welcome to the Zoo :)\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KPOqiLmo6d7t"
      },
      "source": [
        "## More advanced options:\n",
        "\n",
        "- If you would now like to customize the video/plots - i.e., color, dot size, threshold for the point to be plotted (pcutoff), please simply edit the \"config.yaml\" file by updating the values below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGLNVK1q6rIp",
        "outputId": "01dd091e-aa66-4883-92da-39abda1497fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Task': 'myDLC_modelZoo', 'scorer': 'teamDLC', 'date': 'Jul14', 'multianimalproject': False, 'identity': None, 'project_path': '/home/skpark/git/pose-detection-keypoints-estimation-yolov8/deeplabcup/myDLC_modelZoo-teamDLC-2023-07-14', 'video_sets': {'/home/skpark/git/pose-detection-keypoints-estimation-yolov8/deeplabcup/myDLC_modelZoo-teamDLC-2023-07-14/videos/KakaoTalk_20230713_080931355.mp4': {'crop': '0, 640, 0, 360'}}, 'bodyparts': ['Nose', 'L_Eye', 'R_Eye', 'L_Ear', 'R_Ear', 'Throat', 'Withers', 'TailSet', 'L_F_Paw', 'R_F_Paw', 'L_F_Wrist', 'R_F_Wrist', 'L_F_Elbow', 'R_F_Elbow', 'L_B_Paw', 'R_B_Paw', 'L_B_Hock', 'R_B_Hock', 'L_B_Stiffle', 'R_B_Stiffle'], 'start': 0, 'stop': 1, 'numframes2pick': 20, 'skeleton': [['bodypart1', 'bodypart2'], ['objectA', 'bodypart3']], 'skeleton_color': 'black', 'pcutoff': 0.5, 'dotsize': 7, 'alphavalue': 0.7, 'colormap': 'spring', 'TrainingFraction': [0.95], 'iteration': 0, 'default_net_type': 'resnet_50', 'default_augmenter': 'imgaug', 'snapshotindex': -1, 'batch_size': 8, 'cropping': False, 'x1': 0, 'x2': 640, 'y1': 277, 'y2': 624, 'corner2move2': [50, 50], 'move2corner': True}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Updating the plotting within the config.yaml file (without opening it ;):\n",
        "edits = {\n",
        "    'dotsize': 7,  # size of the dots!\n",
        "    'colormap': 'spring',  # any matplotlib colormap!\n",
        "    'pcutoff': 0.5,  # the higher the more conservative the plotting!\n",
        "}\n",
        "deeplabcut.auxiliaryfunctions.edit_config(config_path, edits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vlc0wZgB7R5e",
        "outputId": "90e49da7-49c9-4c1c-ca31-ae5a9222d566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtering with median model /home/skpark/git/pose-detection-keypoints-estimation-yolov8/deeplabcup/myDLC_modelZoo-teamDLC-2023-07-14/videos/KakaoTalk_20230713_080931355.mp4\n",
            "Data from KakaoTalk_20230713_080931355 were already filtered. Skipping...\n",
            "Starting to process video: /home/skpark/git/pose-detection-keypoints-estimation-yolov8/deeplabcup/myDLC_modelZoo-teamDLC-2023-07-14/videos/KakaoTalk_20230713_080931355.mp4\n",
            "Loading /home/skpark/git/pose-detection-keypoints-estimation-yolov8/deeplabcup/myDLC_modelZoo-teamDLC-2023-07-14/videos/KakaoTalk_20230713_080931355.mp4 and data.\n",
            "Labeled video already created. Skipping...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[None]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# re-create the labeled video (first you will need to delete in the folder to the LEFT!):\n",
        "\n",
        "project_path = os.path.dirname(config_path)\n",
        "full_video_path = os.path.join(\n",
        "    project_path,\n",
        "    'videos',\n",
        "    os.path.basename(video_path),\n",
        ")\n",
        "\n",
        "#filter predictions (should already be done above ;):\n",
        "deeplabcut.filterpredictions(config_path, [full_video_path], videotype=videotype)\n",
        "\n",
        "#re-create the video with your edits!\n",
        "deeplabcut.create_labeled_video(config_path, [full_video_path], videotype=videotype,fastmode=True,\n",
        "        save_frames=True, filtered=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtyFt6ey1paB",
        "outputId": "6b6d4ab6-24ed-4020-a7ee-8ecf3b6c724f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting to process video: /home/skpark/git/pose-detection-keypoints-estimation-yolov8/deeplabcup/myDLC_modelZoo-teamDLC-2023-07-14/videos/KakaoTalk_20230713_080931355.mp4\n",
            "Loading /home/skpark/git/pose-detection-keypoints-estimation-yolov8/deeplabcup/myDLC_modelZoo-teamDLC-2023-07-14/videos/KakaoTalk_20230713_080931355.mp4 and data.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duration of video [s]: 6.62, recorded with 24.0 fps!\n",
            "Overall # of frames: 159 with cropped frame dimensions: 640 360\n",
            "Generating frames and creating video.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 159/159 [00:00<00:00, 379.57it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[True]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "deeplabcut.create_labeled_video(config_path,[full_video_path],shuffle=1,videotype=videotype )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UH6o5h2SpaY",
        "outputId": "65902628-1e6e-484f-fdf0-b0619f70aadb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-07-13 02:02:46--  https://iukj.cafe24.com/petbutler/uploads/1689199619487.mp4\n",
            "Resolving iukj.cafe24.com (iukj.cafe24.com)... 183.110.224.9\n",
            "Connecting to iukj.cafe24.com (iukj.cafe24.com)|183.110.224.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19070973 (18M) [video/mp4]\n",
            "Saving to: ‘1689199619487.mp4.1’\n",
            "\n",
            "1689199619487.mp4.1 100%[===================>]  18.19M  11.8MB/s    in 1.5s    \n",
            "\n",
            "2023-07-13 02:02:49 (11.8 MB/s) - ‘1689199619487.mp4.1’ saved [19070973/19070973]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://iukj.cafe24.com/petbutler/uploads/1689199619487.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm3VPeVIMnyZ",
        "outputId": "48085ee0-6346-4304-ae8b-af8939dab436"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using snapshot-75000 for model /home/skpark/git/pose-detection-keypoints-estimation-yolov8/deeplabcup/myDLC_modelZoo-teamDLC-2023-07-14/dlc-models/iteration-0/myDLC_modelZooJul14-trainset95shuffle1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/skpark/.conda/envs/deep310/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting to analyze %  /home/skpark/git/pose-detection-keypoints-estimation-yolov8/data/KakaoTalk_20230713_080931355.mp4\n",
            "Loading  /home/skpark/git/pose-detection-keypoints-estimation-yolov8/data/KakaoTalk_20230713_080931355.mp4\n",
            "Duration of video [s]:  6.62 , recorded with  24.0 fps!\n",
            "Overall # of frames:  159  found with (before cropping) frame dimensions:  640 360\n",
            "Starting to extract posture\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 159/159 [00:14<00:00, 10.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving results in /home/skpark/git/pose-detection-keypoints-estimation-yolov8/data...\n",
            "Saving csv poses!\n",
            "The videos are analyzed. Now your research can truly start! \n",
            " You can create labeled videos with 'create_labeled_video'\n",
            "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
            "Filtering with median model /home/skpark/git/pose-detection-keypoints-estimation-yolov8/data/KakaoTalk_20230713_080931355.mp4\n",
            "Saving filtered csv poses!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting to process video: /home/skpark/git/pose-detection-keypoints-estimation-yolov8/data/KakaoTalk_20230713_080931355.mp4\n",
            "Loading /home/skpark/git/pose-detection-keypoints-estimation-yolov8/data/KakaoTalk_20230713_080931355.mp4 and data.\n",
            "Duration of video [s]: 6.62, recorded with 24.0 fps!\n",
            "Overall # of frames: 159 with cropped frame dimensions: 640 360\n",
            "Generating frames and creating video.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 159/159 [00:00<00:00, 378.10it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[True]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import deeplabcut\n",
        "import os\n",
        "os.chdir('/home/skpark/git/pose-detection-keypoints-estimation-yolov8/deeplabcup')\n",
        "file_name = 'dot_eatin'\n",
        "file_type = 'mp4'\n",
        "iteration = '3'\n",
        "config_path = '/home/skpark/git/pose-detection-keypoints-estimation-yolov8/deeplabcup/myDLC_modelZoo-teamDLC-2023-07-14/config.yaml'\n",
        "target = '/home/skpark/git/pose-detection-keypoints-estimation-yolov8/data/KakaoTalk_20230713_080931355.mp4'\n",
        "#target = deeplabcut.DownSampleVideo(target, width=300)\n",
        "\n",
        "#print(video_path)\n",
        "deeplabcut.analyze_videos(config_path,[target], videotype='.mp4', save_as_csv = True, gputouse=0)\n",
        "\n",
        "deeplabcut.filterpredictions(config_path,[target])\n",
        "\n",
        "#deeplabcut.analyzeskeleton(config_path, [target], videotype='.mp4', shuffle=1, trainingsetindex=0, save_as_csv=True, destfolder=None)\n",
        "\n",
        "deeplabcut.create_labeled_video(config_path, [target], filtered=True, draw_skeleton = True)\n",
        "\n",
        "#deeplabcut.plot_trajectories(config_path,[target],filtered = True, showfigures= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!conda install -c conda-forge cudnn --yes "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.15 (from versions: 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==1.15\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==1.15\n",
        "#!pip install tensorflow-gpu "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'legacy_tf_layers' from 'tensorflow.keras' (/home/skpark/.conda/envs/deeplabcup/lib/python3.11/site-packages/keras/api/_v2/keras/__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m legacy_tf_layers\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'legacy_tf_layers' from 'tensorflow.keras' (/home/skpark/.conda/envs/deeplabcup/lib/python3.11/site-packages/keras/api/_v2/keras/__init__.py)"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "keras.legacy_tf_layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kb2wwiw0_m4",
        "outputId": "4bf6944b-60c1-48a5-863c-536430595f1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.27.1)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.22.4)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.25.1)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.8)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (8.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install moviepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZij75Am00-R",
        "outputId": "d2fdd61e-5729-4a4e-c038-9d4888ac8fe9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Building video /content/output.mp4.\n",
            "Moviepy - Writing video /content/output.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/output.mp4\n"
          ]
        }
      ],
      "source": [
        "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
        "\n",
        "def make_clip_video(path,save_path, start_t, end_t):\n",
        "    clip_video = VideoFileClip(path).subclip(start_t,end_t)\n",
        "    clip_video.write_videofile(save_path)\n",
        "if __name__ == \"__main__\":\n",
        "  make_clip_video('/content/1689077363035.mp4','/content/output.mp4','0', '1')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SoVRDnfd8O7J"
      },
      "source": [
        "이미지 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2QcTW9W8Rg0",
        "outputId": "68f13192-e176-41c2-86da-daeb216deed3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using snapshot-75000 for model /content/myDLC_modelZoo-teamDLC-2023-07-13/dlc-models/iteration-0/myDLC_modelZooJul13-trainset95shuffle1\n",
            "Filtering with median model /content/n_32@2x.png\n",
            "No unfiltered data file found in /content for video n_32@2x and scorer DLC_resnet50_myDLC_modelZooJul13shuffle1_75000.\n",
            "Starting to process video: /content/n_32@2x.png\n",
            "Loading /content/n_32@2x.png and data.\n",
            "No filtered data file found in /content for video n_32@2x and scorer DLC_resnet50_myDLC_modelZooJul13shuffle1_75000.\n"
          ]
        }
      ],
      "source": [
        "deeplabcut.analyze_time_lapse_frames(config_path,'/content/n_32@2x.png',frametype='.png',shuffle=1,\n",
        "                trainingsetindex=0,gputouse=None,save_as_csv=True )\n",
        "deeplabcut.filterpredictions(config_path,['/content/n_32@2x.png'])\n",
        "\n",
        "deeplabcut.create_labeled_video(config_path, ['/content/n_32@2x.png'], filtered=True, draw_skeleton = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.13.1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<module 'keras.layers' from '/home/skpark/.conda/envs/deeplabcup/lib/python3.11/site-packages/keras/layers/__init__.py'>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import keras\n",
        "\n",
        "print(keras.__version__)\n",
        "keras.layers\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a65956563b5422189f053fb30a9cd63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43ca0107ea4142e2b80cc2918967a8c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efc725905dc2443ea97e1516a35932a0",
            "max": 183211667,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b785208d70a34d32a1b30f30497596f1",
            "value": 183211667
          }
        },
        "5e0a992bcd9c4a9f806cb8f46a82b1ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_afdc333a374e48348ea9d50f7194336d",
              "IPY_MODEL_43ca0107ea4142e2b80cc2918967a8c7",
              "IPY_MODEL_deb40f754d8b44d8a4936f6dd95fa5e2"
            ],
            "layout": "IPY_MODEL_b6d9c3ea1d2045d4b0969d12e2dbd52d"
          }
        },
        "78dea5d394ba43bfbb0609bbf412ffbd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85bee6c1211e4cfd90bbdbfb452238fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afdc333a374e48348ea9d50f7194336d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a65956563b5422189f053fb30a9cd63",
            "placeholder": "​",
            "style": "IPY_MODEL_cfce8ea2d40f48469469682dc7600ffd",
            "value": "Downloading (…)n-0_shuffle-0.tar.gz: 100%"
          }
        },
        "b6d9c3ea1d2045d4b0969d12e2dbd52d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b785208d70a34d32a1b30f30497596f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c696e22edc8f495fb6c016f2bb5f34db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DropdownModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "full_human",
              "full_cat",
              "full_dog",
              "primate_face",
              "mouse_pupil_vclose",
              "horse_sideview",
              "full_macaque",
              "superanimal_topviewmouse",
              "superanimal_quadruped"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Choose a DLC ModelZoo model!",
            "description_tooltip": null,
            "disabled": false,
            "index": 2,
            "layout": "IPY_MODEL_78dea5d394ba43bfbb0609bbf412ffbd",
            "style": "IPY_MODEL_f0f13fb4865e47cabcd69119a984a83c"
          }
        },
        "cfce8ea2d40f48469469682dc7600ffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc7e8b5e5bd94478863f4e20cb62de17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "deb40f754d8b44d8a4936f6dd95fa5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85bee6c1211e4cfd90bbdbfb452238fb",
            "placeholder": "​",
            "style": "IPY_MODEL_dc7e8b5e5bd94478863f4e20cb62de17",
            "value": " 183M/183M [00:01&lt;00:00, 104MB/s]"
          }
        },
        "efc725905dc2443ea97e1516a35932a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0f13fb4865e47cabcd69119a984a83c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
